"""
LLM Agent Evaluation Framework

A comprehensive framework for evaluating Large Language Model agents 
across multiple domains with tool-agent-user interaction scenarios.

Based on Ï„-bench methodology for real-world agent evaluation.
"""

__version__ = "0.1.0"
__author__ = "Agent Evaluation Team"