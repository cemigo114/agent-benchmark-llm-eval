# API Keys for LLM Agent Benchmark Framework
# Copy this file to .env and add your actual API keys
# Run: python3 create_env.py for interactive setup

# OpenAI API Key (Required for GPT-4 benchmarks)
# Get from: https://platform.openai.com/api-keys
# Cost: ~$30/1M input tokens, ~$60/1M output tokens for GPT-4o
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic API Key (Required for Claude benchmarks)
# Get from: https://console.anthropic.com/settings/keys  
# Cost: ~$3/1M input tokens, ~$15/1M output tokens for Claude-3.5 Sonnet
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Optional: Google/Vertex AI (for future model support)
# GOOGLE_API_KEY=your-google-api-key-here

# Evaluation Settings
LOG_LEVEL=INFO
MAX_RETRIES=3
REQUEST_TIMEOUT=60

# Benchmark Configuration
# Estimated cost for 3-scenario benchmark: ~$0.04 USD
# Full 70-scenario benchmark estimate: ~$2-6 USD